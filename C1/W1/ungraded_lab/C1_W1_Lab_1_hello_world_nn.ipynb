{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "NwUPJayiVahB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 6]"
      ],
      "metadata": {
        "id": "pAq9-ybdYqAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linspace(-2, 2, 201)\n",
        "x = tf.cast(x, tf.float32)\n",
        "\n",
        "def f(x):\n",
        "  y = x**2 + 2*x - 5\n",
        "  return y\n",
        "\n",
        "y = f(x) + tf.random.normal(shape=[201])\n",
        "\n",
        "plt.plot(x.numpy(), y.numpy(), '.', label='Data')\n",
        "plt.plot(x, f(x), label='Ground truth')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "JYDhwUnTYrYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Randomly generate weight and bias terms\n",
        "    rand_init = tf.random.uniform(shape=[3], minval=0., maxval=5., seed=22)\n",
        "    # Initialize model parameters\n",
        "    self.w_q = tf.Variable(rand_init[0])\n",
        "    self.w_l = tf.Variable(rand_init[1])\n",
        "    self.b = tf.Variable(rand_init[2])\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, x):\n",
        "    # Quadratic Model : quadratic_weight * x^2 + linear_weight * x + bias\n",
        "    return self.w_q * (x**2) + self.w_l * x + self.b"
      ],
      "metadata": {
        "id": "5zl190MgaEKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quad_model = Model()"
      ],
      "metadata": {
        "id": "6mlW0d9Vat-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quad_model"
      ],
      "metadata": {
        "id": "rlOy2KzBav1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_preds(x, y, f, model, title):\n",
        "  plt.figure()\n",
        "  plt.plot(x, y, '.', label='Data')\n",
        "  plt.plot(x, f(x), label='Ground truth')\n",
        "  plt.plot(x, model(x), label='Predictions')\n",
        "  plt.title(title)\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "IRpQBxH4axzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_preds(x, y, f, quad_model, 'Before training')"
      ],
      "metadata": {
        "id": "0lSvqErQa1w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))"
      ],
      "metadata": {
        "id": "5nPZ7OBra5H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "dataset = dataset.shuffle(buffer_size=x.shape[0]).batch(batch_size)"
      ],
      "metadata": {
        "id": "MDJTsrGvbBqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "losses = []\n",
        "\n",
        "# Format training loop\n",
        "for epoch in range(epochs):\n",
        "  for x_batch, y_batch in dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      batch_loss = mse_loss(quad_model(x_batch), y_batch)\n",
        "    # Update parameters with respect to the gradient calculations\n",
        "    grads = tape.gradient(batch_loss, quad_model.variables)\n",
        "    for g,v in zip(grads, quad_model.variables):\n",
        "        v.assign_sub(learning_rate*g)\n",
        "  # Keep track of model loss per epoch\n",
        "  loss = mse_loss(quad_model(x), y)\n",
        "  losses.append(loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Mean squared error for step {epoch}: {loss.numpy():0.3f}')\n",
        "\n",
        "# Plot model results\n",
        "print(\"\\n\")\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
        "plt.title('MSE loss vs training iterations');"
      ],
      "metadata": {
        "id": "ExRRQ0t-bUds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_preds(x, y, f, quad_model, 'After training')"
      ],
      "metadata": {
        "id": "YyNc5aoKcuLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.Sequential([\n",
        "    # create non lenear lamda model x, x**2\n",
        "    tf.keras.layers.Lambda(lambda x: tf.stack([x, x**2], axis=1)),\n",
        "    tf.keras.layers.Dense(units=1, kernel_initializer=tf.random.normal)])\n",
        "\n",
        "new_model.compile(\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n",
        "\n",
        "history = new_model.fit(x, y,\n",
        "                        epochs=100,\n",
        "                        batch_size=32,\n",
        "                        verbose=0)\n",
        "\n",
        "new_model.save('./my_new_model')"
      ],
      "metadata": {
        "id": "Z0sH6UGBc0QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.ylabel('Loss [Mean Squared Error]')\n",
        "plt.title('Keras training progress');"
      ],
      "metadata": {
        "id": "3ibZ7YwadzM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_preds(x, y, f, new_model, 'After Training: Keras')"
      ],
      "metadata": {
        "id": "_2KyT4Nrd66V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7__31pDd_5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "C1_W1_Lab_1_hello_world_nn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}